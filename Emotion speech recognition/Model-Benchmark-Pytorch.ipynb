{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Benckmark Prediction\n",
    "Linear Regression Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits:\n",
    "- https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scipy\n",
    "import scipy\n",
    "\n",
    "#Numpy\n",
    "import numpy as np\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Librosa\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Other  \n",
    "import os\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# Local\n",
    "from source_pytorch.LinearDataset import LinearDatset\n",
    "from source_pytorch.LinearModel import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the parameters and load the data\n",
    "setting = {\n",
    "  \"audio_duration\"  :   4,\n",
    "  \"n_mfcc\"          :   40,\n",
    "  \"sampling_rate\"   :   44100,\n",
    "  \"audio_duration\"  :   4,\n",
    "  \"number_samplig\"  :   354,\n",
    "  \"dataroot\"        :   \".\",\n",
    "  \"batch_size\"      :   10,\n",
    "  \"epochs\"          :   5\n",
    "}\n",
    "\n",
    "pbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the reference\n",
    "ref = pd.read_csv(\"./ReferenceData.csv\")[:37]\n",
    "#Print head / test successfull load\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Train and Test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(ref[\"fname\"]\n",
    "                                                    ,ref[\"label\"]\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=50\n",
    "                                                   )\n",
    "#Split the Train and Validation dataset\n",
    "X_train, X_valid , y_train, y_valid = train_test_split(X_train\n",
    "                                                    , y_train\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=50\n",
    "                                                   )\n",
    "\n",
    "\n",
    "#Merge data and prediction in 1 dataset for train validation and test\n",
    "train_df = pd.concat([X_train,y_train], axis = 1)  \n",
    "valid_df =  pd.concat([X_valid,y_valid], axis = 1)\n",
    "test_df = pd.concat([X_test,y_test], axis = 1)\n",
    "\n",
    "print('Dataset Len:\\t Train - {} \\tValid Dataset - {} \\tTest Dataset - {}'.format(len(train_df), len(valid_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compose DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    LinearDatset(\n",
    "        dataframe=train_df,\n",
    "        n_melspec = setting[\"n_mfcc\"], \n",
    "        sampling_rate = setting[\"sampling_rate\"], \n",
    "        audio_duration= setting[\"audio_duration\"], \n",
    "        number_samples= setting[\"number_samplig\"]\n",
    "        ), \n",
    "    batch_size= setting[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    num_workers=0)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    LinearDatset(\n",
    "        dataframe=valid_df,\n",
    "        n_melspec = setting[\"n_mfcc\"], \n",
    "        sampling_rate = setting[\"sampling_rate\"], \n",
    "        audio_duration= setting[\"audio_duration\"], \n",
    "        number_samples= setting[\"number_samplig\"]\n",
    "    ), \n",
    "    batch_size=setting[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LinearModel()\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Credits: https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_solution.ipynb\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "\n",
    "for epoch in range(1, setting[\"epochs\"]+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_dataloader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_dataloader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_dataloader.sampler)\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('\\n Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "# Load Test Data\n",
    "test_dataloader = DataLoader(\n",
    "    LinearDatset(\n",
    "        dataframe=test_df,\n",
    "        n_melspec = setting[\"n_mfcc\"], \n",
    "        sampling_rate = setting[\"sampling_rate\"], \n",
    "        audio_duration= setting[\"audio_duration\"], \n",
    "        number_samples= setting[\"number_samplig\"]\n",
    "        ), \n",
    "    batch_size= setting[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    num_workers=0)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and evaluate\n",
    "model.eval()\n",
    "\n",
    "right_pred = 0\n",
    "total_pred = 0\n",
    "\n",
    "for data, target in test_dataloader:\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "\n",
    "    for i in range(setting[\"batch_size\"]):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "    total_pred += target.size(0)\n",
    "    right_pred += (pred == target).sum().item()\n",
    "        \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_dataloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "classes = ['angry', 'surprise', 'fearful', 'neutral', 'calm', 'happy', 'sad', 'disgust']\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('Test Total Accuracy %2d%%' % (100 * right_pred / total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit397be61b2f12438a83a89fe139871e40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}